{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSSh/vID3Vb5ivgfT/BUqF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Extraction of apartment sales data in Santiago, Chile**\n",
        "\n",
        "Source: https://www.chilepropiedades.cl\n",
        "\n",
        "@uthor: Víctor E. Núñez\n",
        "\n",
        "Date: \\February 28,2024\n"
      ],
      "metadata": {
        "id": "J6Z96OZ7Ulg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Libraries**"
      ],
      "metadata": {
        "id": "PUvvI0VTUkz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from lxml import html\n",
        "import re\n",
        "import time\n",
        "import numpy as np, pandas as pd"
      ],
      "metadata": {
        "id": "mOlIt9pAU4CX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Scraping**"
      ],
      "metadata": {
        "id": "GFsp-2_5U_zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/181.0.0.0 Safari/537.36\",\n",
        "}\n",
        "\n",
        "class Content:\n",
        "    def __init__(self,Address, Price_CLP, Price_UF, HOA_fees, Bedrooms,\n",
        "                 Bathrooms, Floor, Garage, Total_area, Usable_area,Interior,\n",
        "                 Exterior, Services, Flooring_type, Description, Nearby_amenities,\n",
        "                 Category, Publication_date, Real_estate_agent, Publication_ID, Link):\n",
        "        self.Address =  Address\n",
        "        self.Link = Link\n",
        "        self.Price_CLP = Price_CLP\n",
        "        self.Price_UF = Price_UF\n",
        "        self.HOA_fees =  HOA_fees\n",
        "        self.Bedrooms = Bedrooms\n",
        "        self.Bathrooms =  Bathrooms\n",
        "        self.Floor =  Floor\n",
        "        self.Garage = Garage\n",
        "        self.Total_area = Total_area\n",
        "        self.Usable_area =  Usable_area\n",
        "        self.Interior =  Interior\n",
        "        self.Exterior = Exterior\n",
        "        self.Services =  Services\n",
        "        self.Flooring_type =  Flooring_type\n",
        "        self.Description =  Description\n",
        "        self.Nearby_amenities =  Nearby_amenities\n",
        "        self.Category =  Category\n",
        "        self.Publication_date =  Publication_date\n",
        "        self.Real_estate_agent =  Real_estate_agent\n",
        "        self.Publication_ID =  Publication_ID\n",
        "\n",
        "\n",
        "    def to_dataframe(self):\n",
        "        data = {\n",
        "            'Address': self.Address,\n",
        "            'Price_CLP': self.Price_CLP,\n",
        "            'Price_UF': self.Price_UF,\n",
        "            'HOA_fees': self.HOA_fees,\n",
        "            'Bedrooms': self.Bedrooms,\n",
        "            'Bathrooms': self.Bathrooms,\n",
        "            'Floor': self.Floor,\n",
        "            'Garage': self.Garage,\n",
        "            'Total_area': self.Total_area,\n",
        "            'Usable_area': self.Usable_area,\n",
        "            'Interior': self.Interior,\n",
        "            'Exterior': self.Exterior,\n",
        "            'Services': self.Services,\n",
        "            'Flooring_type': self.Flooring_type,\n",
        "            'Description': self.Description,\n",
        "            'Nearby_amenities': self.Nearby_amenities,\n",
        "            'Category': self.Category,\n",
        "            'Publication_date': self.Publication_date,\n",
        "            'Real_estate_agent': self.Real_estate_agent,\n",
        "            'Publication_ID': self.Publication_ID,\n",
        "            'Link': self.Link\n",
        "        }\n",
        "        df = pd.DataFrame(data)\n",
        "        return df\n",
        "\n",
        "\n",
        "def getSoup(url):\n",
        "    req = requests.get(url, headers = headers)\n",
        "    soup = BeautifulSoup(req.text, 'html.parser')\n",
        "    parser = html.fromstring(req.content)\n",
        "    return soup, parser\n",
        "\n",
        "def InternalLinks(url):\n",
        "    internalLinks = []\n",
        "    soup, parser = getSoup(url)\n",
        "    links =  soup.find_all('a', href = re.compile(r'/ver-publicacion/venta/.*', re.IGNORECASE))\n",
        "    for link in links:\n",
        "        link = 'https://chilepropiedades.cl'+link.get('href')\n",
        "        if link not in internalLinks:\n",
        "            internalLinks.append(link)\n",
        "    return internalLinks\n",
        "\n",
        "\n",
        "def ScrapePage(url,numPage,delay):\n",
        "\n",
        "    #Adjusting the page extraction limit.\n",
        "    soup, parser =  getSoup(url)\n",
        "    total_pages = int(soup.find_all('a', class_= \"page-link\")[-1].get('href').split('/')[-1])\n",
        "\n",
        "    if numPage > total_pages:\n",
        "        numPage = total_pages\n",
        "\n",
        "    print('Extracting data from a total of {} pages of apartments in {}:'.format(numPage, url.split('/')[-2]) )\n",
        "    print(' ')\n",
        "\n",
        "    Address = []; Link = [];\n",
        "    Price_CLP = []; Price_UF = [];\n",
        "    HOA_fees = []; Bedrooms = [];\n",
        "    Bathrooms = []; Floor = [];\n",
        "    Garage = [];\n",
        "    Total_area = []; Usable_area = [];\n",
        "    Category = [];\n",
        "    Publication_date = []; Publication_ID = [];\n",
        "    Interior = []; Exterior=[];\n",
        "    Flooring_type = []; Services = [];\n",
        "    Description = []; Nearby_amenities = [];\n",
        "    Real_estate_agent = [];\n",
        "    url_ = url\n",
        "    while numPage != 0:\n",
        "\n",
        "        links =  InternalLinks(url_)\n",
        "        for element in links:\n",
        "            soup,parser = getSoup(element)\n",
        "\n",
        "            #Link------------------------------------------------------\n",
        "            Link.append(element)\n",
        "            #Address-------------------------------------------------\n",
        "            try:\n",
        "                Address.append(soup.find('h1').get_text().replace('\\n', '').strip())\n",
        "            except:\n",
        "                Address.append(np.nan)\n",
        "\n",
        "            #-----------------------------------------------------------\n",
        "            #-----------------------------------------------------------\n",
        "\n",
        "            dict={}\n",
        "            for key,value in zip(soup.find_all('div', class_ = \"clp-description-label col-6\"),\n",
        "                                 soup.find_all('div', class_ = \"clp-description-value col-6\")\n",
        "                                ):\n",
        "                key =  key.get_text().strip()\n",
        "                value =  value.get_text().replace('  ','').strip()\n",
        "                dict[key] =  value\n",
        "\n",
        "            #-----------------------------------------------------------\n",
        "           #Price\n",
        "            try:\n",
        "                if dict['Valor (CLP aprox.)*:']:\n",
        "                    Valor_CLP_ = dict['Valor (CLP aprox.)*:'].split()[1]\n",
        "                    Price_CLP.append(Valor_CLP_)\n",
        "                    Valor_UF_  = dict['Valor:'].split()[1]\n",
        "                    Price_UF.append(Valor_UF_)\n",
        "            except:\n",
        "                Valor_CLP_  = dict['Valor:'].split()[1]\n",
        "                Price_CLP.append(Valor_CLP_)\n",
        "                Valor_UF_ = dict['Valor (UF aprox.)*:'].split()[1]\n",
        "                Price_UF.append(Valor_UF_)\n",
        "\n",
        "\n",
        "            #HOA--------------------------------------------\n",
        "            try:\n",
        "                HOA_fees.append(dict['Gastos Comunes:'].split()[1])\n",
        "            except:\n",
        "                HOA_fees.append(np.nan)\n",
        "            #Bedrooms----------------------------------------------\n",
        "            try:\n",
        "                Bedrooms.append(int(dict['Habitaciones:']))\n",
        "            except:\n",
        "                Bedrooms.append(np.nan)\n",
        "            #Bathrooms-----------------------------------------------------\n",
        "            try:\n",
        "                Bathrooms.append(int(dict['Baño:']))\n",
        "            except:\n",
        "                Bathrooms.append(np.nan)\n",
        "            #Floor--------------------------------------------------------\n",
        "            try:\n",
        "                Floor.append(int(dict['Piso:']))\n",
        "            except:\n",
        "                Floor.append(np.nan)\n",
        "            #Garage------------------------------------------\n",
        "            try:\n",
        "                Garage.append(int(dict['Estacionamientos:']))\n",
        "            except:\n",
        "                Garage.append('No')\n",
        "            #Total Area-------------------------------------------------\n",
        "            try:\n",
        "                Total_area.append(dict['Superficie Total:'])\n",
        "            except:\n",
        "                Total_area.append(np.nan)\n",
        "            #Usable Area-------------------------------------------\n",
        "            try:\n",
        "                Usable_area.append(dict['Superficie Útil:'])\n",
        "            except:\n",
        "                Usable_area.append(np.nan)\n",
        "\n",
        "            #----------------------------------------------------------\n",
        "            #----------------------------------------------------------\n",
        "\n",
        "            dict_2 = {}\n",
        "\n",
        "            for key,value in zip(soup.find_all('div', class_ = \"col-6 clp-description-label\"),\n",
        "                                 soup.find_all('div', class_ = \"col-6 clp-description-value\")\n",
        "                                ):\n",
        "                key =  key.get_text().strip()\n",
        "                value =  value.get_text().replace('  ','').strip()\n",
        "                dict_2[key] =  value\n",
        "            #----------------------------------------------------------\n",
        "            #Category--------------------------------------------------\n",
        "            try:\n",
        "                Category.append(dict_2['Tipo de propiedad:'])\n",
        "            except:\n",
        "                Category.append(np.nan)\n",
        "            #Publication date------------------------------------------\n",
        "            try:\n",
        "                Publication_date.append(dict_2['Fecha Publicación:'])\n",
        "            except:\n",
        "                Publication_date.append(np.nan)\n",
        "            #ID--------------------------------------------------------\n",
        "            try:\n",
        "                Publication_ID.append(dict_2['Código aviso:'])\n",
        "            except:\n",
        "                Publication_ID.append(np.nan)\n",
        "            #----------------------------------------------------------\n",
        "            # Services\n",
        "            #----------------------------------------------------------\n",
        "            serv_ = {}\n",
        "            if soup.find('ul', class_=\"clp-equipment-list\"):\n",
        "                for element in soup.find('ul', class_=\"clp-equipment-list\").get_text().strip().split('\\n')[:4]:\n",
        "                    try:\n",
        "                        key = element.split(':')[0]\n",
        "                        value = element.split(':')[1]\n",
        "                        serv_[key] = value\n",
        "                    except:\n",
        "                        None\n",
        "\n",
        "            else:\n",
        "                serv_['Interior'] = np.nan\n",
        "                serv_['Exterior'] = np.nan\n",
        "                serv_['Servicios'] = np.nan\n",
        "                serv_['Piso'] = np.nan\n",
        "\n",
        "            #Interior--------------------------------------------------------\n",
        "            try:\n",
        "                Interior.append(serv_['Interior'])\n",
        "            except:\n",
        "                Interior.append(np.nan)\n",
        "            #Exterior--------------------------------------------------------\n",
        "            try:\n",
        "                Exterior.append(serv_['Exterior'])\n",
        "            except:\n",
        "                Exterior.append(np.nan)\n",
        "            #Services--------------------------------------------------------\n",
        "            try:\n",
        "                Services.append(serv_['Servicios'])\n",
        "            except:\n",
        "                Services.append(np.nan)\n",
        "            #Flooring type---------------------------------------------------\n",
        "            try:\n",
        "                Flooring_type.append(serv_['Piso'])\n",
        "            except:\n",
        "                Flooring_type.append(np.nan)\n",
        "\n",
        "            #Description-----------------------------------------------------\n",
        "            text =[]\n",
        "            if soup.find('div', class_=\"clp-description-box\"):\n",
        "                try:\n",
        "                    for element in soup.find('div', class_=\"clp-description-box\"):\n",
        "                        text.append(element.get_text().strip())\n",
        "                    Description.append(\" \".join(text))\n",
        "                except:\n",
        "                    Description.append(np.nan)\n",
        "            else:\n",
        "                Description.append(np.nan)\n",
        "            #Nearby_amenitiess ---------------------------------------------\n",
        "            if soup.find_all('h2', string = 'Comodidades y Lugares de Interés'):\n",
        "                try:\n",
        "                    list_ = []\n",
        "                    for div in soup.find_all('div', class_= 'amenity-text'):\n",
        "                        Nearby_amenities_ = div.find('p').get_text().replace('', '').split('\\n')\n",
        "                        Nearby_amenities_ = list(filter(lambda x: x.strip(), Nearby_amenities_))\n",
        "                        list_.append(Nearby_amenities_[0].strip()+' ('+Nearby_amenities_[-1].strip()+')')\n",
        "                    Nearby_amenities.append(list_)\n",
        "                except:\n",
        "                    Nearby_amenities.append(np.nan)\n",
        "            else:\n",
        "                Nearby_amenities.append(np.nan)\n",
        "            #Real_estate_agent or Relator-----------------------------------\n",
        "            if soup.find_all('h2', string='Corredora'):\n",
        "                try:\n",
        "                    Real_estate_agent_ = soup.find('div', class_= \"col-sm-8 clp-user-contact-details-table\").find('a').get_text()\n",
        "                    Real_estate_agent.append(Real_estate_agent_)\n",
        "                except:\n",
        "                    Real_estate_agent.append(np.nan)\n",
        "            else:\n",
        "                Real_estate_agent.append(np.nan)\n",
        "\n",
        "\n",
        "        time.sleep(delay)\n",
        "        numPage = numPage-1\n",
        "        if numPage == 0:\n",
        "            break\n",
        "        next_soup, next_ṕarser = getSoup(url_)\n",
        "        url_ = next_soup.find('link', {'rel':'next'}).get('href')\n",
        "\n",
        "    return Content(Address,Price_CLP,Price_UF,HOA_fees, Bedrooms,\n",
        "                   Bathrooms, Floor, Garage, Total_area, Usable_area, Interior,\n",
        "                   Exterior, Services, Flooring_type, Description, Nearby_amenities, Category,\n",
        "                   Publication_date,Real_estate_agent, Publication_ID ,Link)\n",
        "\n",
        "\n",
        "# Creating empty DataFrames.\n",
        "dataframe1 = pd.DataFrame()\n",
        "dataframe2 = pd.DataFrame()\n",
        "dataframe3 = pd.DataFrame()\n",
        "dataframe4 = pd.DataFrame()\n",
        "dataframe5 = pd.DataFrame()\n",
        "dataframe6 = pd.DataFrame()\n",
        "dataframe7 = pd.DataFrame()\n",
        "dataframe8 = pd.DataFrame()\n",
        "\n",
        "for element in ['santiago','las-condes', 'nunoa', 'providencia', 'estacion-central',\n",
        "               'san-miguel', 'vitacura', 'independencia']:\n",
        "    start_url = 'https://chilepropiedades.cl/propiedades/venta/departamento/{}/0'.format(element)\n",
        "\n",
        "    #Start Extraction:\n",
        "    content = ScrapePage(start_url,2,2)\n",
        "\n",
        "    new_df = content.to_dataframe()  # Call the to_dataframe() method of the Content object.\n",
        "\n",
        "    # Determine which DataFrame corresponds and concatenate the new DataFrame.\n",
        "    if element == 'santiago':\n",
        "        dataframe1 = pd.concat([dataframe1, new_df],axis = 0, ignore_index=True)\n",
        "    elif element == 'las-condes':\n",
        "        dataframe2 = pd.concat([dataframe2, new_df], ignore_index=True)\n",
        "    elif element == 'nunoa':\n",
        "        dataframe3 = pd.concat([dataframe3, new_df], ignore_index=True)\n",
        "    elif element == 'providencia':\n",
        "        dataframe4 = pd.concat([dataframe4, new_df], ignore_index=True)\n",
        "    elif element == 'estacion-central':\n",
        "        dataframe5 = pd.concat([dataframe5, new_df], ignore_index=True)\n",
        "    elif element == 'san-miguel':\n",
        "        dataframe6 = pd.concat([dataframe6, new_df], ignore_index=True)\n",
        "    elif element == 'vitacura':\n",
        "        dataframe7 = pd.concat([dataframe7, new_df], ignore_index=True)\n",
        "    elif element == 'independencia':\n",
        "        dataframe8 = pd.concat([dataframe8, new_df], ignore_index=True)\n",
        "\n",
        "\n",
        "final_df = pd.concat([dataframe1, dataframe2, dataframe3, dataframe4,\n",
        "                     dataframe5, dataframe6, dataframe7, dataframe8], axis = 0).reset_index(drop =  True)\n",
        "#Save\n",
        "final_df.to_csv('./Dataset_DeptoStgoCHL.csv')\n",
        "\n",
        "print('¡Extraction completed.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j46PBj5sVKfQ",
        "outputId": "29e397d0-9b9b-4019-88b5-82521a19e5e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data from a total of 2 pages of apartments in santiago:\n",
            " \n",
            "Extracting data from a total of 2 pages of apartments in las-condes:\n",
            " \n",
            "Extracting data from a total of 2 pages of apartments in nunoa:\n",
            " \n",
            "Extracting data from a total of 2 pages of apartments in providencia:\n",
            " \n",
            "Extracting data from a total of 2 pages of apartments in estacion-central:\n",
            " \n",
            "Extracting data from a total of 2 pages of apartments in san-miguel:\n",
            " \n",
            "Extracting data from a total of 2 pages of apartments in vitacura:\n",
            " \n",
            "Extracting data from a total of 2 pages of apartments in independencia:\n",
            " \n",
            "¡Extraction completed.\n",
            "CPU times: user 33.9 s, sys: 424 ms, total: 34.3 s\n",
            "Wall time: 1min 42s\n"
          ]
        }
      ]
    }
  ]
}